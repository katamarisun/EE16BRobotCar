{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIXT33N Project\n",
    "## Phase 3: PCA/Classificiation - Voice Commands\n",
    "\n",
    "### EE 16B: Designing Information Devices and Systems II, Fall 2016\n",
    "\n",
    "Written by Nathaniel Mailoa and Emily Naviasky (2016)\n",
    "\n",
    "nmailoa@berkeley.edu &emsp; enaviasky@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name 1**:\n",
    "\n",
    "**Login**: ee16b-\n",
    "\n",
    "\n",
    "**Name 2**:\n",
    "\n",
    "**Login**: ee16b-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [Part 1: Data Collection](#part1)\n",
    "* [Part 2: Principal Component Analysis](#part2)\n",
    "* [Part 3: Classification](#part3)\n",
    "* [Part 4: Launchpad Implementation](#part4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "In this version of the project, SIXT33N is an obedient little robot that will follow the directions that you shout at it. There are four moves that SIXT33N can make: move straight, move straight slowly, turn righ, and turn left. However, SIXT33N does not speak human languages, and some words, like \"left\" and \"right\", sound very similar while other words, like \"port\" and \"starboard\", are easy to distinguish. Your job in this phase is to find four command words that are easy for SIXT33N to tell apart.\n",
    "\n",
    "For phase 3, you will develop the PCA classifier that allows SIXT33N to tell the difference between the four commands. You will examine several different test words, and determine which ones will be easiest to sort by PCA.\n",
    "\n",
    "Once you have some sample data collected, you will develop a model in this iPython Notebook (since iPython has pretty graphs and lots of computing power, and a Launchpad does not). You will perform PCA and look at how well it separates the sample data to get an idea of what words might be easily distingused. Then, once you have a set of four words that you like, you will use k-means to automatically classify them. When you (and your GSI) are satisfied with the classifier's accuracy, you will port the classifier into the Launchpad code in Energia. However, since your Launchpad has so much less computing power than your PC, you will examine ways to optimize the classification before you port it.\n",
    "\n",
    "The goals of this phase are as follows:\n",
    "- Generate envelope, threshold to get snippets\n",
    "- PCA + Classifier (2-3 commands)\n",
    "- Check accuracy\n",
    "- PCA projection on Launchpad\n",
    "\n",
    "As mentioned in the main project page, there is a checkpoint every week. Each checkpoint is worth 5 points, and if you are late you are awarded 4 points. The checkpoints are due in the beginning of the lab in the week after. For this phase, the checkpoints (marked **<span style=\"color:green\">green</span>** in the Notebook) are:\n",
    "- Week 1: First pass through PCA with sample data; GSI feedback\n",
    "- Week 2: Classification target met in Python\n",
    "\n",
    "Note: The Week 2 checkpoint is not due until the end of the Integration Phase (week of 11/29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "## <span style=\"color:blue\">Part 1: Data Collection</span>\n",
    "\n",
    "### Materials\n",
    "- Microphone front-end circuit\n",
    "- Launchpad + USB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When humans distinguish words, they listen for temporal and frequency differneces to determine what is being said. However, SIXT33N does not have the memory or the processing power to distinguish words nearly as well as our human brains, so we will have to choose much simpler features for SIXT33N to look at.\n",
    "\n",
    "When you think of speech signals, you might notice that the shape of the speech wave is a very distinctive part of each word. Taking just the shape of the magnitude of a signal is called enveloping, exemplified in the image below. So, we want to do some filtering to retrieve the envelope of the audio signal. We can then train the PCA off of just this envelope and build a classifier to classify new data points.\n",
    "\n",
    "<center>\n",
    "<img width=\"500px\" src=\"http://inst.eecs.berkeley.edu/~ee16b/fa15/lab_pics/proj-envelope.png\">\n",
    "</center>\n",
    "\n",
    "Keeping in mind that the words that look most different have different shapes (or different amplitudes varied over time), brainstorm four or five words that you think will sort well.\n",
    "\n",
    "**<span style=\"color:red\">What words are you going to try? Why?</span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, upload the sketch <b>`collect-data-envelope.ino`</b> to your Launchpad. This sketch gathers ADC samples every 0.35ms, and streams the data back to the PC. This code also sets some pins to input pins, which is required for the microphone board to work.\n",
    "\n",
    "Next, hook up your front end circuit. Make sure to disconnect the 5V jumper on the Launchpad, because you will power the Launchpad from the power supply. <b>Make sure to keep the jumper on just the pin closest to the USB and put it back at the end of the lab.</b> \n",
    "\n",
    "<center>\n",
    "<img width=\"400px\" src=\"http://inst.eecs.berkeley.edu/~ee16b/fa15/lab_pics/msp-jumpers.png\">\n",
    "</center>\n",
    "\n",
    "Do not power up your circuit for now, we will connect the appropriate Launchpad pins to your circuit first:\n",
    "- P6.0 to the microphone front end circuit output\n",
    "- 3.3V pin to the 3V power rail of the breadboard (in particular to supply the buffer op-amp)\n",
    "- 5V pin to the 5V power rail of the breadboard\n",
    "- GND pin to the ground rail of the breadboard\n",
    "\n",
    "Next, use the bench power supply to provide 5V to the circuit. **<span color='red'>DO NOT FORGET TO SET THE CURRENT LIMIT.</span>** Before you start recording, use the oscilloscope to probe the output of the microphone circuit. Make sure the waveform averages to 1.65V (halfway between 0V and 3.3V) and the amplitude is large enough. Make a noise at the microphone; you should see the signal change to reflect the sound you just made. If you are close enough or loud enough, you should be able to get the peak-to-peak amplitude of your signal all the way up to 3V.\n",
    "\n",
    "<center>\n",
    "<img width=\"400px\" src=\"http://inst.eecs.berkeley.edu/~ee16b/sp16/lab_pics/proj-waveform.png\">\n",
    "</center>\n",
    "\n",
    "Say one of the words you have chosen into the microphone and look at the scope as you say it. Try saying it softly then try shouting it. Notice how the signal gets distorted when the sound is too loud? Good audio data is loud enough that noises from the rest of the room don't show up too much, but quiet enough that the signal doesn't get distorted when it saturates the output. Position your self and monitor how loud you are speaking so that the voice samples you want to collect are loud but not distorted.\n",
    "\n",
    "You should already have <b>`collect-data-envelope.ino`</b> uploaded to your Launchpad. This sketch will turn on the red Launchpad LED to show that it is recording. The Launchpad will record 2 seconds of audio at a time, sampled every 0.35ms. \n",
    "\n",
    "<b>The red LED on the launch pad is like a recording room. When the red light goes on the Launchpad is recording. Say the word you want to record before the red LED turns off.</b>\n",
    "\n",
    "To make your life easier, pronounce the words consistently. Try <b>five or six words</b> that you think will classify well. The Launchpad will apply an enveloping function (discussed later) which reduces the data from several thousand samples to 172 samples. \n",
    "\n",
    "Now, you have a voice sample in the Launchpad but it is deleted as soon as the light flashes again. How do you get the data out and onto the PC where you can use it? Make sure the Launchpad is connected to a USB. Then, to transfer the data in the PC, run:\n",
    "\n",
    "<b>`python collect-data-envelope.py log.csv`</b>\n",
    "\n",
    "Now, each time the light flashes and a sample is collected by the Launchpad, it will be written into to `log.csv`. You might want to probe the output and watch the scope while you collect. After you collect, a few test words, check the `log.csv` and make sure that it looks like an sound wave and is not just full of zeros. It might help to plot the data to make sure.\n",
    "\n",
    "\n",
    "Collect around <b>15 good samples</b> for each of your four to five words, and be sure to save them to different .csv files with descriptive names. You will collect more once you settle on the four words that sort well enough.\n",
    "\n",
    "#### For your Consideration:\n",
    "\n",
    "Once you have your four or more words collected, you can move onto the PCA classification below. You may realize in the next section that one or two of your words are not sorting quite as well as you would like. Don't be afraid to come back to this section and try collecting different words based on what you have learned makes a word sortable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "## <span style=\"color:blue\">Part 2: Principal Component Analysis</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use the recorded data for PCA, we must first process the data. It is not necessary for you to understand the enveloping function well enough to implement it (since we have already done it for you), but just in case you are curious the enveloping function is described in the following pseudocode:\n",
    "\n",
    "<code><b>Enveloping function</b>\n",
    "Divide the whole signal to a block of 16 samples\n",
    "For each chunk:\n",
    "    Find the mean of the chunk\n",
    "    Subtract each sample by the mean\n",
    "    Find the sum of the absolute value of each sample\n",
    "</code>\n",
    "\n",
    "What you really need to know, however, is what the enveloped signal looks like for each word. Spend a little time looking at the data you just collected in the python plots below.\n",
    "\n",
    "First, load the recorded data from the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.io\n",
    "import scipy.cluster\n",
    "from scipy import interpolate\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        r = csv.reader(csvfile, delimiter=' ')\n",
    "        for row in r:\n",
    "            data.append([float(i) for i in row[0].split(',')])\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data from csv\n",
    "# YOUR CODE HERE\n",
    "word1 = \n",
    "word2 =\n",
    "word3 = \n",
    "word4 =\n",
    "\n",
    "# Take the same number of readings for all words to be fair\n",
    "num_samples = min(np.shape(word1)[0], np.shape(word2)[0], np.shape(word3)[0], np.shape(word4)[0])\n",
    "word1 = word1[:num_samples,:]\n",
    "word2 = word2[:num_samples,:]\n",
    "word3 = word3[:num_samples,:]\n",
    "word4 = word4[:num_samples,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your data and get a feel for how it looks enveloped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot all word1 samples\n",
    "plt.plot(word1.T)\n",
    "plt.show()\n",
    "plt.plot(word2.T)\n",
    "plt.show()\n",
    "plt.plot(word3.T)\n",
    "plt.show()\n",
    "plt.plot(word4.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the speech is only a small part of the 2 second window, and each sample starts at different times. PCA is not good at interpreting delay, so we need to somehow start in the same place each time and capture a smaller segment of the 2 second sample where the speech is present. To do this, we will use a thresholding algorithm.\n",
    "\n",
    "First, we define a `threshold` relative to the maximum value of the data. We say that any signal that crosses the threshold is the start of a speech command. In order to not lose the first couple samples of the speech command, we say that the command starts `pre_length` samples before the threshold is crossed. We then take a window of the data that is `length` long, and try to capture the entire sound of the command in that window.\n",
    "\n",
    "Play around with the parameters `length`, `pre_length` and `threshold` in the cells below to find appropriate values corresponding to your voice and chosen commands. You should see the results and how much of your command you captured in the plots generated below. When you are satisfied, note down the values of `length`, `pre_length` and `threshold` - <b>you will need to add them to the Launchpad sketch later.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_snippets(data, length, pre_length, thres):\n",
    "    data_out = np.zeros((np.shape(data)[0], length))\n",
    "    \n",
    "    for rnum, row in enumerate(data):\n",
    "        # Find the threshold\n",
    "        row_thres = thres*np.max(row)\n",
    "\n",
    "        # Figure out when interesting snippet starts\n",
    "        block = pre_length\n",
    "        while (row[block] < row_thres):\n",
    "            block = block + 1\n",
    "        block = min(block, 172 - length)\n",
    "        data_out[rnum,:] = row[block-pre_length:block-pre_length+length]\n",
    "        \n",
    "        # Normalization\n",
    "        data_out[rnum,:] = data_out[rnum,:] / np.sum(data_out[rnum,:])\n",
    "        \n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = 40        # Adjust this\n",
    "pre_length = 5     # Adjust this\n",
    "threshold = 0.5    # Adjust this\n",
    "\n",
    "word1_snippets = get_snippets(word1, length, pre_length, threshold)\n",
    "plt.plot(word1_snippets.T)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "word2_snippets = get_snippets(word2, length, pre_length, threshold)\n",
    "plt.plot(word2_snippets.T)\n",
    "plt.show()\n",
    "word3_snippets = get_snippets(word3, length, pre_length, threshold)\n",
    "plt.plot(word3_snippets.T)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "word4_snippets = get_snippets(word4, length, pre_length, threshold)\n",
    "plt.plot(word4_snippets.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a mostly organized set of samples for each word. Can you tell the which word is which just by the envelope? Can you tell them apart? If you can't tell the words apart, then PCA will have a difficult time as well.\n",
    "\n",
    "Now that we have our data in a nice format, we can build the PCA input matrix from that data. The function `np.vstack` might be helpful here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #\n",
    "A = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the following SVD code on your matrix A, plot the sigma values and do a projection to get a base line of how well it works.\n",
    "\n",
    "Once you get an idea of how well your data sorts on its own, you might want to experiment with using other types of pre-processing on your matrix A. For example, zero-meaning might have interesting results. Let processed_A be A with some signal processing applied to it.\n",
    "\n",
    "\n",
    "**<span style=\"color:red\">What processing techniques did you try on the matrix and and what was the result?</span>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero-mean the matrix A. Note down the mean for the Launchpad code\n",
    "# YOUR CODE HERE #\n",
    "processed_A = A ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take the SVD of matrix A\n",
    "# YOUR CODE HERE #\n",
    "[u,s,v] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot out the sigma values\n",
    "plt.stem(s)\n",
    "plt.xlim([-1,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at your sigma values. They should show you very clearly how many principal components you need.\n",
    "\n",
    "**<span style=\"color:red\">How many principal components do you need? Given that you are storting 4 words, is the the number you expected to need?</span>** \n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the principal component(s)\n",
    "# YOUR CODE HERE #\n",
    "plt.plot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now project the data in the matrix A onto the new basis and plot it. Do you see clustering? Do you think you can separate the data easily? If not, you might need to try new words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Project the data onto the new basis\n",
    "# YOUR CODE HERE #\n",
    "proj = \n",
    "\n",
    "plt.scatter(proj[0:num_samples,0], proj[0:num_samples,1], c=['blue'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples:num_samples*2,0], proj[num_samples:num_samples*2,1], c=['red'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples*2:num_samples*3,0], proj[num_samples*2:num_samples*3,1], c=['green'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples*3:num_samples*4,0], proj[num_samples*3:num_samples*4,1], c=['orange'], edgecolor='none')\n",
    "plt.legend(['word1', 'word2', 'word3', 'word4'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:green\">**First pass through PCA with sample data.** Show your GSI the result of the projection and talk about how you might be able to improve the result.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your data might look noisy, and might not classify perfectly. That is completely okay, we are just looking for good enough. Like many AI applications, this is noisy data that we are classifying so some error in classification is okay. The important part is if you think that you can see some clustering. \n",
    "\n",
    "Once you think you have decent clustering, you can move on to getting your code to automate classification and you will make up for some of the error there, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "## <span style=\"color:blue\">Part 3:  K-Means Classification</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the plot above, we will define a way of classifying the different words. Fill in the skeleton code below to classify a vector in your new basis. \n",
    "\n",
    "Use a few of speech samples you collected at the beginning and test your classification on them. <b>Don't forget to do the same processing on these samples that you trained with</b> (i.e. do zero-mean by subtracting the mean of the original matrix A).\n",
    "\n",
    "You will use k-means to classify, just as you did in the your BMI homework question. If you need a refresher, you can check the python documentation for the function scipy.cluster.vq.kmeans <a href=\"http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.kmeans.html#scipy.cluster.vq.kmeans\">here</a>.\n",
    "\n",
    "You need to be a little careful when creating the classifying algorithm since we do not want SIXT33N to pick up random sounds and treat them as one of the commands. To do this, pick a reasonably tight boundary for your classification.\n",
    "\n",
    "Note: The order in which the centroids is returned is nondeterministic - save the centroid values and matching word somewhere safe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_centroids(clustered_data, num_of_clusters):\n",
    "    \"\"\" Use scipy.cluster.vq.kmeans to determine centroids of clusters\n",
    "    Parameters:\n",
    "        clustered_data: the data already projected onto the new basis\n",
    "        num_of_clusters: the expected number of clusters in the data\n",
    "    Returns: \n",
    "        The centroids of the clusters\n",
    "    Note: You do NOT need to call the whiten function\n",
    "    \"\"\"\n",
    "    ...\n",
    "    return (...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine the centroids of each cluster\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "\n",
    "# Print the centroid locations\n",
    "centroid1 = ...\n",
    "centroid2 = ...\n",
    "centroid3 = ...\n",
    "centroid4 = ...\n",
    "\n",
    "print('The first centroid is at: ' + str(centroid1))\n",
    "print('The second centroid is at: ' + str(centroid2))\n",
    "print('The third centroid is at: ' + str(centroid3))\n",
    "print('The fourth centroid is at: ' + str(centroid4))\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(proj[0:num_samples,0], proj[0:num_samples,1], c=['blue'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples:num_samples*2,0], proj[num_samples:num_samples*2,1], c=['red'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples*2:num_samples*3,0], proj[num_samples*2:num_samples*3,1], c=['green'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples*3:num_samples*4,0], proj[num_samples*3:num_samples*4,1], c=['orange'], edgecolor='none')\n",
    "\n",
    "plt.scatter(centroid_list[:,0], centroid_list[:,1], c=['yellow'], marker='*', s=300)\n",
    "plt.legend(['word1', 'word2', 'word3', 'word4'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(data_point):\n",
    "    \"\"\"\n",
    "    Classifies a new reading vector into a word.\n",
    "    Inputs:\n",
    "        data_point: new data point vector (before projection)\n",
    "    Output:\n",
    "        Word number\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try out the classification function\n",
    "print(classify(processed_A[0,:])) # Modify to use other vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will check the accuracy of your classification. <b>Our target is for the classifier to classify at least 80% correctly on all four words.</b> Write code to apply the `classify` function to each sample and check whether the classification is accurate. Compute the accuracy of classifying each word correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to classify the whole A matrix\n",
    "word1_good = 0;\n",
    "word1_bad = 0;\n",
    "word2_good = 0;\n",
    "word2_bad = 0;\n",
    "word3_good = 0;\n",
    "word3_bad = 0;\n",
    "word4_good = 0;\n",
    "word4_bad = 0;\n",
    "\n",
    "for (i,row) in enumerate(processed_A):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "print(\"Percent Correct of Word 1 = \", ...)\n",
    "print(\"Percent Correct of Word 2 = \", ...)\n",
    "print(\"Percent Correct of Word 3 = \", ...)\n",
    "print(\"Percent Correct of Word 4 = \", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='30px' align='left' src=\"http://inst.eecs.berkeley.edu/~ee16b/sp16/lab_pics/check.png\">\n",
    "<br/>\n",
    "## <span style=\"color:green\">CHECKPOINT 1</span>\n",
    " <span style=\"color:green\">**Show your GSI the plot of data with centroids and that you can classify the words with 80% accuracy.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part4'></a>\n",
    "## <span style=\"color:blue\">Part 4: Launchpad Implementation</span>\n",
    "\n",
    "### Materials\n",
    "- Microphone front-end circuit\n",
    "- Launchpad + USB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will walk you through taking the signal procesing that you just developed above and translating it from python to C that will go on your launchpad. In addition, you will need to transfer the PCA vector and mean you found here into the launchpad. To do so, simply run the block below and copy each output into the Launchpad code.\n",
    "\n",
    "You may also use this code for any other vectors that you need in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = ''\n",
    "for i in v[0,:].T:\n",
    "    a += str(i) + ', '\n",
    "print(\"PC1\")\n",
    "print(a)\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your last step will be to implement your <b>data processing</b> and <b>classification</b> (just the projection, not the PCA) in the Launchpad sketch <b>`classify.ino`</b>. Energia uses the Arduino language, which is very close to C. If you need a refresher or a quick start, there are many C tutorials in the web. Quickly glance through <b>`classify.ino`</b>. It contains the same base code as the <b>`collect-data-envelope.ino`</b> from before, with some extra functionality. Since Energia does not have as many in-built functions as Python, you might have to write out the functions yourself. For example, a dot product should be written as:\n",
    "\n",
    "`float result = 0;`<br/>\n",
    "`for (i=0; i<LENGTH; i++){`<br/>\n",
    "&emsp; `result += vector1[i]*vector2[i];`<br/>\n",
    "`}`\n",
    "\n",
    "For debugging purposes, printing looks like the line below. The Launchpad will print the string out in Energia's Serial Monitor through the USB cable.\n",
    "\n",
    "<code>Serial.println(\"I'm being printed!\");</code>\n",
    "\n",
    "Open up <b>`classify.ino`</b> and get a feel for what some of the code is doing. Note that there are 2 code blocks (A1 and B) that you need to modify. <b>You should not have to change anything else outside these marked code blocks.</b> \n",
    "\n",
    "First, fill in some constant parameters in **`CODE BLOCK A1`**. The `SNIPPET_SIZE`, `PRELENGTH` and `THRESHOLD` constants are found from the arguments to the enveloping function in the PCA classification phase. \n",
    "\n",
    "The `KMEANS_THRESHOLD` is the variable we suggest you use to decide whether to accept or regect a classification depending on a sample's distance from the closest centroid. If the L2 norm (distance) is larger than the threshold, your classification algorithm should simply ignore it and wait for the next sample. Look at the plot of sample data and the centroids from the PCA Notebook and approximate a radius around the centroids that capture most of the data. Try to be conservative - it's better to not classify than to misclassify.\n",
    "\n",
    "The `LOUDNESS_THRESHOLD` variable decides whether to accept a classification depending on the amplitude of the recorded data. If the recorded data is too soft, we do not want to classify it as it is probably noise. Since the loudness unit is arbitrary, start by using `700`. Later, if the Launchpad classifies noise, increase this constant. If it misses a lot of speech (i.e. thinks your word is noise), decrease this constant.\n",
    "\n",
    "Secondly, fill in the arrays in **`CODE BLOCK A2`**. These are the PCA bases and mean vector, as well as the K-means classification centroids. If you need more than 2 principal components, add a new `pca_vec3` array. Remember, if you are using more than two principal components, then the dimensionality of all of your point and the centriods has increased. The centroid arrays should be the same length as the number of principal components you use. An example of filling up an array of 3 rather than two elements is shown below for syntax.\n",
    "\n",
    "<code>float centriod1[3] = {0.1234, 0.5678, 0.9012};</code>\n",
    "\n",
    "Now go to **`CODE BLOCK B`**. This is the meat of the classification. Before this block, the call to `envelope` leaves the data vector in the array called `result`. You will write the code to project this data array onto your new PCA basis. Remember that you will still need to subtract the mean vector, before doing a dot product for each basis. We recommend using the variables `proj1` and `proj2` to store the projection results.\n",
    "\n",
    "Next, code the K-means classification using the centroid arrays. Find the distance between the projected data point and each centroid using the function `l2_norm` (for 2 principal components) or `l2_norm3` (for 3 principal components). These functions take the data point coordinates and the centroid array. Look up the function definition in the sketch. Out of the 4 centroids, find the one with the smallest L2 norm from the data point. This is the word you classified.\n",
    "\n",
    "Before saying you have classified a word, however, you will want to check the distance first. If the distance is greater than `KMEANS_THRESHOLD`, the data point is not close enough for you to guess with some certainty. Thus, we only consider a data point to be classified if the distance is less than this constant.\n",
    "\n",
    "When you have classified a data point, print out the word on Serial. You should be able to see the printout from Energia's Serial Monitor.\n",
    "\n",
    "Before running the code in the Launchpad, use the oscilloscope to probe the circuit output again and make sure that it still averages around 1.65V. Now upload the sketch to your Launchpad and run it. Open the Serial Monitor and press the reset button. Say your word and the Launchpad should recognize your word as it gets printed on the Serial Monitor!\n",
    "\n",
    "If the Launchpad does not classify as well as you think it should, remember to play with the `KMEANS_THRESHOLD` and `LOUDNESS_THRESHOLD` variables. To debug the sketch, you can also print out any of the variables you have used. \n",
    "\n",
    "Voila! Your SIXT33N can recognize your words! If you still have time, help the controls pair finish their phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='30px' align='left' src=\"http://inst.eecs.berkeley.edu/~ee16b/sp16/lab_pics/check.png\">\n",
    "<br/>\n",
    "## <span style=\"color:green\">CHECKPOINT 2</span>\n",
    " <span style=\"color:green\">**Show your GSI the Launchpad recognizing words.** Make sure the correct identified word is printed in the Serial Monitor.</span>\n",
    " (Note: This is due the week of the Integration lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
